import os

import streamlit as st
from dotenv import load_dotenv
from langchain.chains import LLMChain
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

load_dotenv()


def _get_api_key() -> str | None:
    if "OPENAI_API_KEY" in st.secrets:
        return st.secrets["OPENAI_API_KEY"]
    return os.getenv("OPENAI_API_KEY")

# -----------------------------------------------------
# 1. LLMå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆæ¡ä»¶ã§å¿…é ˆï¼‰
# -----------------------------------------------------
def run_llm(input_text: str, expert_type: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ï¼ˆA or Bï¼‰ã‚’å—ã‘å–ã‚Šã€
    LangChain ã‚’ä½¿ã£ã¦ LLM ã‹ã‚‰ã®å›ç­”ã‚’è¿”ã™é–¢æ•°ã€‚
    """

    # å°‚é–€å®¶ã”ã¨ã® system ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    expert_system_messages = {
        "A. ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£æˆ¦ç•¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ": "ã‚ãªãŸã¯ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£æˆ¦ç•¥ã«ç²¾é€šã—ãŸå°‚é–€å®¶ã§ã™ã€‚ç’°å¢ƒãƒ»ç¤¾ä¼šãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹ã®è¦³ç‚¹ã‹ã‚‰å®Ÿç¾å¯èƒ½æ€§ã‚’è©•ä¾¡ã—ã€å®Ÿè·µçš„ãªææ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚",
        "B. DXãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼": "ã‚ãªãŸã¯ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã«å¼·ã„å°‚é–€å®¶ã§ã™ã€‚æœ€æ–°ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’æ´»ã‹ã—ãŸæ¥­å‹™æ”¹å–„æ–½ç­–ã‚’æ§‹é€ çš„ã«æç¤ºã—ã¦ãã ã•ã„ã€‚",
    }

    system_message = expert_system_messages.get(expert_type, "ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")

    api_key = _get_api_key()
    if not api_key:
        raise RuntimeError("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ Streamlit ã® secrets ã« OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    # LangChain ChatPromptTemplate
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message),
            ("user", "{user_input}")
        ]
    )

    # LLMè¨­å®šï¼ˆGPT-4o-mini ãªã©ç’°å¢ƒã«å¿œã˜ã¦å¤‰æ›´å¯ï¼‰
    llm = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0.6,
        openai_api_key=api_key,
    )

    chain = LLMChain(llm=llm, prompt=prompt)

    # LLMã«æŠ•ã’ã¦å¿œç­”ã‚’å–å¾—
    response = chain.run({"user_input": input_text})

    return response


# -----------------------------------------------------
# 2. Streamlit UI
# -----------------------------------------------------
st.title("ğŸ” AIå°‚é–€å®¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ï¼ˆLangChain + Streamlitï¼‰")

st.caption("Streamlit Community Cloud ã® Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ 3.11 ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚")

st.write("""
## ğŸ“ ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦
- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é¸æŠã—ãŸå°‚é–€å®¶ã®è¦–ç‚¹ã§AIãŒå›ç­”ã—ã¾ã™ã€‚  
- ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£é ˜åŸŸï¼ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©é ˜åŸŸã®å°‚é–€å®¶ã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚  
- Lesson8 ã®å†…å®¹ã‚’ãƒ™ãƒ¼ã‚¹ã« LangChain ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚  
""")

st.write("---")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼ˆå°‚é–€å®¶é¸æŠï¼‰
expert = st.radio(
    "AI ã«ã©ã®å°‚é–€å®¶ã¨ã—ã¦å›ç­”ã•ã›ã¾ã™ã‹ï¼Ÿ",
    [
        "A. ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£æˆ¦ç•¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ",
        "B. DXãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼",
    ]
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_input("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("å›ç­”ã‚’ç”Ÿæˆ"):
    if user_input.strip() == "":
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
            try:
                answer = run_llm(user_input, expert)
            except RuntimeError as exc:
                st.error(str(exc))
            else:
                st.success("å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
                st.write("## ğŸ“˜ å›ç­”")
                st.write(answer)
        